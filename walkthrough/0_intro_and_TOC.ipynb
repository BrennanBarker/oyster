{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining Pearls of Wisdom from Oyster\n",
    "### A Walkthrough of Graphical Causal Inference with the Oyster Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction <a id=\"intro\"></a>\n",
    "Learn Oyster in this walkthrough of graphical causal inference methods. Most sections feature a selected example from Judea Pearl's *Causal Inference in Statistics: A Primer*, a book I highly recommend for those interested in the nuts and bolts of causal inference.  This walkthrough focuses on study questions from the Primer that are graphical in nature; analytic questions from the Primer are best addressed with a statistics-focused software package (such as `statsmodels` in Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements <a id=\"ack\"></a>\n",
    "This notebook was inspired by a [similar approach](http://dagitty.net/primer/) from Johannes Textor, Andrew Forney, and Judea Pearl to teaching selected examples from Pearl's Primer using the R package `Daggity`.  [Daggity](http://www.dagitty.net) is excellent software and readers familiar with R are encouraged to explore it.  Daggity also has an intuitive [web-based interface](http://www.dagitty.net/dags.html).\n",
    "\n",
    "Oyster employs several algorithms developed by Pearl as well as Ilya Shpitser, Jian Tian, Johannes Textor, Benito van der Zander, and others.  As Oyster's documentation is futher developed it will contain references to their relevant papers.  I am grateful to all of these people and many more for their excellent work in developing the field of causal inference.\n",
    "\n",
    "I am also indebted to the developers of the excellent [NetworkX](https://networkx.github.io) package, which serves as the backbone for Oyster's graphical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a id='toc'></a>\n",
    "\n",
    "#### [Introduction](#intro)\n",
    "\n",
    "#### [Acknowledgements](#ack)\n",
    "\n",
    "#### [Preliminaries](1_preliminaries.ipynb/#prelim)\n",
    "- [What are Causal Diagrams?](1_preliminaries.ipynb/#causalDiagrams)\n",
    "- [Creating and Drawing Causal Diagrams](1_preliminaries.ipynb/#create)\n",
    "- [Ancestry in Causal Diagrams](1_preliminaries.ipynb/#ancestry)\n",
    "    - [Study Question 1.4.1](1_preliminaries.ipynb/#sq141)\n",
    "- [Paths in Causal Diagrams](1_preliminaries.ipynb/#paths)\n",
    "    - [Study Question 1.4.1 cont'd](1_preliminaries.ipynb/#sq141contd)\n",
    "- [Causal Diagrams as an Abstraction of Structural Equations](1_preliminaries.ipynb/#sems)\n",
    "    - [Study Question 1.5.1](1_preliminaries.ipynb/#sq151)\n",
    "\n",
    "#### [Applications of Causal Diagrams](2_applications_of_causal_diagrams.ipynb/#apps)\n",
    "- [Independence and D-separation](2_applications_of_causal_diagrams.ipynb#d_sep)\n",
    "    - [Study question 2.3.1](2_applications_of_causal_diagrams.ipynb/#sq231)\n",
    "- [Implied Independencies and Testable Implications](2_applications_of_causal_diagrams.ipynb/#impliedIndependencies)\n",
    "    - [Study question 2.4.1](2_applications_of_causal_diagrams.ipynb/#sq241)\n",
    "- [Causal Diagram Analysis for Prediction and Variable Selection](2_applications_of_causal_diagrams.ipynb/#predictionAndVariableSelection)\n",
    "    - [Study question 2.4.1, cont'd](2_applications_of_causal_diagrams.ipynb/#sq241contd)\n",
    "- [Equivalence Classes and CPDAGs for Causal Search and Alternative Hypotheses](2_applications_of_causal_diagrams.ipynb/#cpdag)\n",
    "    - [Study question 2.5.1](2_applications_of_causal_diagrams.ipynb/#sq251)\n",
    "- [A Graphical Algorithm for D-Separation](2_applications_of_causal_diagrams.ipynb/#d_sep_graph)\n",
    "\n",
    "#### [Examining the Effects of Interventions with Causal Diagrams](3_interventions.ipynb/#interventions)\n",
    "- [Computing Causal Effects from Observational Data](3_interventions.ipynb/#observational)\n",
    "- [Identifying Adjustment Sets with the Back-Door Criterion](3_interventions.ipynb/#backdoor)\n",
    "    - [Study question 3.3.1](3_interventions.ipynb/#sq331)\n",
    "- [Justifying Adjustment Procedures with Causal Diagrams](3_interventions.ipynb/#arg)\n",
    "    - [Study question 3.3.2 (Lord's Paradox)](3_interventions.ipynb/#sq332)\n",
    "- [Identifying Adjustment Sets with the Front-Door Criterion](3_interventions.ipynb/#frontdoor)\n",
    "    - [Study Question 3.4.1](3_interventions.ipynb/#sq341)\n",
    "- [Specific Effects as Multipurpose Tool for Analysis](3_interventions.ipynb/#specific)\n",
    "    - [Study question 3.5.1](3_interventions.ipynb/#sq351)\n",
    "- [Instrumental Variables and Research Design](3_interventions.ipynb/#iv)\n",
    "- [General Identifiability](3_interventions.ipynb/#id)\n",
    "\n",
    "#### [Counterfactuals](3_interventions.ipynb/#counterfactuals) (Under Construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
